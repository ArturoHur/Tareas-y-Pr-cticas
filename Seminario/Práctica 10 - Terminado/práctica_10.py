# -*- coding: utf-8 -*-
"""Práctica 10.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/11oWxGZClop1tgujxp7HKbfxfw0O42puP
"""

import numpy as np

class MyPerceptron:
    def __init__(self, num_inputs):
        self.weights = np.random.rand(num_inputs)
        self.bias = 1
        self.learning_rate = 0.01

    def activation(self, x):
        return 1 / (1 + np.exp(-x))

    def make_prediction(self, inputs):
        activation_level = np.dot(self.weights, inputs) + self.bias
        prediction = self.activation(activation_level)
        return 1 if prediction >= 0.5 else 0

    def train_neuron(self, inputs, targets, epochs):
        for epoch in range(epochs):
            # Actualizar ponderaciones y sesgos según el error de predicción para cada entrada
            for i in range(len(inputs)):
                prediction = self.make_prediction(inputs[i])
                error = targets[i] - prediction
                self.weights += self.learning_rate * error * inputs[i]
                self.bias += self.learning_rate * error

    def assess_accuracy(self, inputs, targets):
        correct_predictions = sum(1 for i in range(len(inputs)) if self.make_prediction(inputs[i]) == targets[i])
        accuracy = correct_predictions / len(inputs)
        return accuracy


num_inputs = 2
num_epochs = 100
neuron = MyPerceptron(num_inputs)


##################### Entrenamiento para la Compuerta Lógica AND #####################

input_data = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])
output_targets = np.array([0, 0, 0, 1])

num_inputs = 2
num_epochs = 100

# Entrenamiento del Perceptrón
my_perceptron = MyPerceptron(num_inputs)
my_perceptron.train_neuron(input_data, output_targets, num_epochs)

# Prueba del perceptrón entrenado
print("Prueba con datos de entrenamiento para la compuerta lógica AND:")
for i in range(len(input_data)):
    prediction = my_perceptron.make_prediction(input_data[i])
    print(f'Entrada: {input_data[i]}, Predicción: {prediction}')

# Calcular la exactitud en los datos de prueba
accuracy = my_perceptron.assess_accuracy(input_data, output_targets)

print(f'Exactitud del Modelo en los Datos de Prueba: {accuracy * 100:.2f}%')

##################### Entrenamiento para la Compuerta Lógica AND #####################


##################### Entrenamiento para la Compuerta Lógica OR #####################

inputs_or = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])
targets_or = np.array([0, 1, 1, 1])
epochs_or = 100
input_size_or = 2

perceptron_or = MyPerceptron(input_size_or)
perceptron_or.train_neuron(inputs_or, targets_or, epochs_or)

# Prueba del perceptrón entrenado con datos de entrenamiento
print("\n")
print("Prueba con datos de entrenamiento para la compuerta lógica OR:")
for i in range(len(inputs_or)):
    prediction = perceptron_or.make_prediction(inputs_or[i])
    print(f'Entrada: {inputs_or[i]}, Predicción: {prediction}')

# Calcular la exactitud en los datos de prueba
accuracy_or = perceptron_or.assess_accuracy(inputs_or, targets_or)
print(f'Exactitud en los datos de prueba para la compuerta lógica OR: {accuracy_or * 100:.2f}%')

##################### Entrenamiento para la Compuerta Lógica OR #####################